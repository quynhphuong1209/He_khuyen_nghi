# -*- coding: utf-8 -*-
"""Qu·ª≥nh Ph∆∞∆°ng 3_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14uFEK-UPcfQC6fOvSm78sUNjEJjgY6-P

# =============================
# B√ÄI T·∫¨P 3: Lu·∫≠t k·∫øt h·ª£p cho h·ªá khuy·∫øn ngh·ªã
# =============================
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import os
import urllib.request
import zipfile

ml_100k_url = 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'
ml_100k_zip = 'ml-100k.zip'
ml_100k_folder = 'ml-100k'

if not os.path.exists(ml_100k_folder):
    if not os.path.exists(ml_100k_zip):
        print('Downloading MovieLens 100K dataset...')
        urllib.request.urlretrieve(ml_100k_url, ml_100k_zip)
    print('Extracting MovieLens 100K dataset...')
    with zipfile.ZipFile(ml_100k_zip, 'r') as zip_ref:
        zip_ref.extractall('.')

# ƒê·ªçc d·ªØ li·ªáu ƒë√°nh gi√°
ratings_cols = ['userID', 'itemID', 'rating', 'timestamp']
ratings_df = pd.read_csv('ml-100k/u.data', sep='\t', names=ratings_cols, encoding='latin-1')

ratings_df.head()

# TODO: Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu ƒë√°nh gi√° th√†nh d·ªØ li·ªáu giao d·ªãch
# 1. L·ªçc c√°c ƒë√°nh gi√° cao (rating >= 4)
high_rating_df = ratings_df[ratings_df['rating'] >= 4]
# L∆∞u d·ªØ li·ªáu ƒë√£ l·ªçc ra file CSV (kh√¥ng ghi index ƒë·ªÉ tr√°nh c·ªôt s·ªë th·ª© t·ª±)
high_rating_df.to_csv('high_ratings.csv', index=False)
# ƒê·ªçc l·∫°i file ƒë√£ l·ªçc
filtered_df = pd.read_csv('high_ratings.csv')
# Ki·ªÉm tra k·∫øt qu·∫£
filtered_df.head()

# TODO: √Åp d·ª•ng thu·∫≠t to√°n Apriori
# 1. Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu giao d·ªãch th√†nh ƒë·ªãnh d·∫°ng ma tr·∫≠n nh·ªã ph√¢n
#T·∫°o danh s√°ch giao d·ªãch: m·ªói ng∆∞·ªùi d√πng -> danh s√°ch phim (ID)
transactions = high_rating_df.groupby('userID')['itemID'].apply(list)

#  M√£ h√≥a danh s√°ch giao d·ªãch th√†nh ma tr·∫≠n nh·ªã ph√¢n
te = TransactionEncoder()
te_array = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_array, columns=te.columns_)

# 2. T√¨m t·∫≠p m·ª•c th∆∞·ªùng xuy√™n
frequent_itemsets = apriori(df_encoded, min_support=0.1, use_colnames=True)

# 3. T·∫°o lu·∫≠t k·∫øt h·ª£p
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.4)

# Xem k·∫øt qu·∫£
rules.head()

# TODO: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng lu·∫≠t
# 1. Ph√¢n t√≠ch ƒë·ªô h·ªó tr·ª£, ƒë·ªô tin c·∫≠y v√† ƒë·ªô n√¢ng
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go

# L·ªçc top 10 lu·∫≠t theo lift
top_rules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\
                .sort_values(by='lift', ascending=False).head(10)

# Hi·ªÉn th·ªã b·∫£ng ƒë·∫πp b·∫±ng plotly (ƒë√£ √©p ki·ªÉu int ‚Üí str)
fig = go.Figure(data=[go.Table(
    header=dict(values=["Antecedents", "Consequents", "Support", "Confidence", "Lift"],
                fill_color='lightblue',
                align='left'),
    cells=dict(values=[
        [', '.join([str(i) for i in a]) for a in top_rules['antecedents']],
        [', '.join([str(i) for i in c]) for c in top_rules['consequents']],
        top_rules['support'].round(3),
        top_rules['confidence'].round(3),
        top_rules['lift'].round(3)
    ],
    fill_color='lavender',
    align='left'))
])
fig.update_layout(title="Top 10 Association Rules by Lift", width=1000, height=400)
fig.show()

# 2. Tr·ª±c quan h√≥a c√°c lu·∫≠t t·ªët nh·∫•t
plt.figure(figsize=(10,6))
sns.scatterplot(data=rules, x='support', y='confidence', size='lift', hue='lift', sizes=(20, 200), palette='viridis')
plt.title('Scatter plot of Association Rules')
plt.xlabel('Support')
plt.ylabel('Confidence')
plt.grid(True)
plt.show()

# TODO: X√¢y d·ª±ng h·ªá khuy·∫øn ngh·ªã d·ª±a tr√™n lu·∫≠t
# def recommend_movies(user_movies, rules, top_n=10):
#     recommendations = []
#     for _, rule in rules.iterrows():
#         antecedents = set(rule['antecedents'])
#         if antecedents.issubset(user_movies):
#             for movie in rule['consequents']:
#                 if movie not in user_movies:
#                     recommendations.append((movie, rule['confidence'], rule['lift']))
#
#     # S·∫Øp x·∫øp theo ƒë·ªô tin c·∫≠y v√† ƒë·ªô n√¢ng
#     recommendations.sort(key=lambda x: (x[1], x[2]), reverse=True)
#     return recommendations[:top_n]
# H√†m khuy·∫øn ngh·ªã phim d·ª±a tr√™n lu·∫≠t k·∫øt h·ª£p
def recommend_movies(user_movies, rules, top_n=10):
    recommendations = []
    for _, rule in rules.iterrows():
        antecedents = set(rule['antecedents'])
        if antecedents.issubset(user_movies):
            for movie in rule['consequents']:
                if movie not in user_movies:
                    try:
                        movie_int = int(movie)
                        recommendations.append((movie_int, rule['confidence'], rule['lift']))
                    except:
                        continue  # b·ªè qua n·∫øu kh√¥ng chuy·ªÉn ƒë∆∞·ª£c sang int

    # S·∫Øp x·∫øp theo ƒë·ªô tin c·∫≠y v√† ƒë·ªô n√¢ng
    recommendations.sort(key=lambda x: (x[1], x[2]), reverse=True)
    return recommendations[:top_n]


# ================================
# G·ªçi th·ª≠ h√†m khuy·∫øn ngh·ªã
# ================================

user_movies = {1, 50}  # Gi·∫£ s·ª≠ ng∆∞·ªùi d√πng ƒë√£ xem phim c√≥ ID 1 v√† 50

# G·ªçi h√†m khuy·∫øn ngh·ªã
recommendations = recommend_movies(user_movies, rules, top_n=10)

# ƒê·ªçc d·ªØ li·ªáu t√™n phim
movies_df = pd.read_csv(
    'ml-100k/u.item',
    sep='|',
    encoding='latin-1',
    header=None,
    usecols=[0, 1],
    names=['itemID', 'title']
)
movie_dict = dict(zip(movies_df['itemID'], movies_df['title']))

# In k·∫øt qu·∫£
if recommendations:
    print("üé¨ G·ª£i √Ω phim cho ng∆∞·ªùi d√πng:")
    for movie, confidence, lift in recommendations:
        movie_name = movie_dict.get(movie, f'Phim ID {movie}')
        print(f"- {movie_name} | ƒê·ªô tin c·∫≠y: {confidence:.2f} | ƒê·ªô n√¢ng: {lift:.2f}")
else:
    print("‚ö†Ô∏è Kh√¥ng c√≥ g·ª£i √Ω ph√π h·ª£p v·ªõi l·ªãch s·ª≠ ng∆∞·ªùi d√πng.")